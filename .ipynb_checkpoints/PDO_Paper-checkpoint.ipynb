{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import netCDF4\n",
    "import csv\n",
    "import rasterio\n",
    "import scipy\n",
    "import subprocess\n",
    "#from osgeo import gdal\n",
    "#from osgeo import osr\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import netcdf \n",
    "from scipy.ndimage import gaussian_filter\n",
    "from netCDF4 import Dataset\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Directory and Get List of Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to V3 Files:  ./data/ABoVE_ReSALT_InSAR_PolSAR_V3_2004/data/\n",
      "Version 3 Files:\n",
      "PDO_ReSALT_chevak_2017_03.nc4\n",
      "1 PDO_ReSALT_chevak_2017_03.nc4\n",
      "PDO_ReSALT_denali_2017_03.nc4\n",
      "2 PDO_ReSALT_denali_2017_03.nc4\n",
      "PDO_ReSALT_kougar_2017_03.nc4\n",
      "3 PDO_ReSALT_kougar_2017_03.nc4\n",
      "PDO_ReSALT_noatak_2017_03.nc4\n",
      "4 PDO_ReSALT_noatak_2017_03.nc4\n",
      "PDO_ReSALT_lclark_2017_03.nc4\n",
      "5 PDO_ReSALT_lclark_2017_03.nc4\n",
      "PDO_ReSALT_gdhope_2017_03.nc4\n",
      "6 PDO_ReSALT_gdhope_2017_03.nc4\n",
      "PDO_ReSALT_dhorse_2017_03.nc4\n",
      "7 PDO_ReSALT_dhorse_2017_03.nc4\n",
      "PDO_ReSALT_oldcrB_2017_03.nc4\n",
      "8 PDO_ReSALT_oldcrB_2017_03.nc4\n",
      "PDO_ReSALT_wriglN_2017_03.nc4\n",
      "9 PDO_ReSALT_wriglN_2017_03.nc4\n",
      "PDO_ReSALT_mcpher_2017_03.nc4\n",
      "10 PDO_ReSALT_mcpher_2017_03.nc4\n",
      "PDO_ReSALT_fsmitN_2017_03.nc4\n",
      "11 PDO_ReSALT_fsmitN_2017_03.nc4\n",
      "PDO_ReSALT_teller_2017_03.nc4\n",
      "12 PDO_ReSALT_teller_2017_03.nc4\n",
      "PDO_ReSALT_atqasu_2017_03.nc4\n",
      "13 PDO_ReSALT_atqasu_2017_03.nc4\n",
      "PDO_ReSALT_snagyk_2017_03.nc4\n",
      "14 PDO_ReSALT_snagyk_2017_03.nc4\n",
      "PDO_ReSALT_ivotuk_2017_03.nc4\n",
      "15 PDO_ReSALT_ivotuk_2017_03.nc4\n",
      "PDO_ReSALT_provid_2017_03.nc4\n",
      "16 PDO_ReSALT_provid_2017_03.nc4\n",
      "PDO_ReSALT_ykdelt_2017_03.nc4\n",
      "17 PDO_ReSALT_ykdelt_2017_03.nc4\n",
      "PDO_ReSALT_koyukk_2017_03.nc4\n",
      "18 PDO_ReSALT_koyukk_2017_03.nc4\n",
      "PDO_ReSALT_wolfcr_2017_03.nc4\n",
      "19 PDO_ReSALT_wolfcr_2017_03.nc4\n",
      "PDO_ReSALT_nwells_2017_03.nc4\n",
      "20 PDO_ReSALT_nwells_2017_03.nc4\n",
      "PDO_ReSALT_faberl_2017_03.nc4\n",
      "21 PDO_ReSALT_faberl_2017_03.nc4\n",
      "PDO_ReSALT_tukhwy_2017_03.nc4\n",
      "22 PDO_ReSALT_tukhwy_2017_03.nc4\n",
      "PDO_ReSALT_oldcrA_2017_03.nc4\n",
      "23 PDO_ReSALT_oldcrA_2017_03.nc4\n",
      "PDO_ReSALT_deltaj_2017_03.nc4\n",
      "24 PDO_ReSALT_deltaj_2017_03.nc4\n",
      "PDO_ReSALT_ambler_2017_03.nc4\n",
      "25 PDO_ReSALT_ambler_2017_03.nc4\n",
      "PDO_ReSALT_scoaoi_2017_03.nc4\n",
      "26 PDO_ReSALT_scoaoi_2017_03.nc4\n",
      "PDO_ReSALT_barrow_2017_03.nc4\n",
      "27 PDO_ReSALT_barrow_2017_03.nc4\n",
      "PDO_ReSALT_yflats_2017_03.nc4\n",
      "28 PDO_ReSALT_yflats_2017_03.nc4\n",
      "PDO_ReSALT_bonanz_2017_03.nc4\n",
      "29 PDO_ReSALT_bonanz_2017_03.nc4\n",
      "PDO_ReSALT_toolik_2017_03.nc4\n",
      "30 PDO_ReSALT_toolik_2017_03.nc4\n",
      "PDO_ReSALT_aklavi_2017_03.nc4\n",
      "31 PDO_ReSALT_aklavi_2017_03.nc4\n",
      "PDO_ReSALT_poorma_2017_03.nc4\n",
      "32 PDO_ReSALT_poorma_2017_03.nc4\n",
      "PDO_ReSALT_coldfo_2017_03.nc4\n",
      "33 PDO_ReSALT_coldfo_2017_03.nc4\n",
      "PDO_ReSALT_ftreso_2017_03.nc4\n",
      "34 PDO_ReSALT_ftreso_2017_03.nc4\n",
      "PDO_ReSALT_kluanB_2017_03.nc4\n",
      "35 PDO_ReSALT_kluanB_2017_03.nc4\n",
      "PDO_ReSALT_watson_2017_03.nc4\n",
      "36 PDO_ReSALT_watson_2017_03.nc4\n",
      "PDO_ReSALT_snarer_2017_03.nc4\n",
      "37 PDO_ReSALT_snarer_2017_03.nc4\n",
      "PDO_ReSALT_katmai_2017_03.nc4\n",
      "38 PDO_ReSALT_katmai_2017_03.nc4\n",
      "PDO_ReSALT_kakisB_2017_03.nc4\n",
      "39 PDO_ReSALT_kakisB_2017_03.nc4\n",
      "PDO_ReSALT_kakisA_2017_03.nc4\n",
      "40 PDO_ReSALT_kakisA_2017_03.nc4\n",
      "PDO_ReSALT_yellow_2017_03.nc4\n",
      "41 PDO_ReSALT_yellow_2017_03.nc4\n",
      "PDO_ReSALT_daring_2017_03.nc4\n",
      "42 PDO_ReSALT_daring_2017_03.nc4\n",
      "PDO_ReSALT_huslia_2017_03.nc4\n",
      "43 PDO_ReSALT_huslia_2017_03.nc4\n",
      "PDO_ReSALT_kluanA_2017_03.nc4\n",
      "44 PDO_ReSALT_kluanA_2017_03.nc4\n",
      "PDO_ReSALT_behcho_2017_03.nc4\n",
      "45 PDO_ReSALT_behcho_2017_03.nc4\n",
      "PDO_ReSALT_scotty_2017_03.nc4\n",
      "46 PDO_ReSALT_scotty_2017_03.nc4\n",
      "PDO_ReSALT_counci_2017_03.nc4\n",
      "47 PDO_ReSALT_counci_2017_03.nc4\n",
      "PDO_ReSALT_sriver_2017_03.nc4\n",
      "48 PDO_ReSALT_sriver_2017_03.nc4\n",
      "PDO_ReSALT_inigok_2017_03.nc4\n",
      "49 PDO_ReSALT_inigok_2017_03.nc4\n",
      "PDO_ReSALT_anaktu_2017_03.nc4\n",
      "50 PDO_ReSALT_anaktu_2017_03.nc4\n",
      "PDO_ReSALT_fsmitS_2017_03.nc4\n",
      "51 PDO_ReSALT_fsmitS_2017_03.nc4\n",
      "Total Number of V3 Files:  51\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Path to Version 3 directory\n",
    "V3_path  = \"./data/ABoVE_ReSALT_InSAR_PolSAR_V3_2004/data/\"\n",
    "out_path = './output/'\n",
    "\n",
    "print(\"Path to V3 Files: \", V3_path)\n",
    "\n",
    "# get all files in the directory\n",
    "#dir_tree = os.walk(V3_path)\n",
    "#for dirpath, dirnames, filenames in dir_tree:\n",
    "#    pass\n",
    "filenames = os.listdir(V3_path)\n",
    "\n",
    "\n",
    "# find all the netcdf V3 files\n",
    "print('Version 3 Files:')\n",
    "file_list = []\n",
    "num_files = 0\n",
    "for file in filenames:\n",
    "    print(file)\n",
    "    if file.endswith('.nc4'):\n",
    "        file_list.append(file)\n",
    "        num_files=num_files+1\n",
    "        print(num_files,file)\n",
    "\n",
    "print('Total Number of V3 Files: ', num_files)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/ABoVE_ReSALT_InSAR_PolSAR_V3_2004/data/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['PDO_ReSALT_chevak_2017_03.nc4',\n",
       " 'PDO_ReSALT_denali_2017_03.nc4',\n",
       " 'PDO_ReSALT_kougar_2017_03.nc4',\n",
       " 'PDO_ReSALT_noatak_2017_03.nc4',\n",
       " 'PDO_ReSALT_lclark_2017_03.nc4',\n",
       " 'PDO_ReSALT_gdhope_2017_03.nc4',\n",
       " 'PDO_ReSALT_dhorse_2017_03.nc4',\n",
       " 'PDO_ReSALT_oldcrB_2017_03.nc4',\n",
       " 'PDO_ReSALT_wriglN_2017_03.nc4',\n",
       " 'PDO_ReSALT_mcpher_2017_03.nc4',\n",
       " 'PDO_ReSALT_fsmitN_2017_03.nc4',\n",
       " 'PDO_ReSALT_teller_2017_03.nc4',\n",
       " 'PDO_ReSALT_atqasu_2017_03.nc4',\n",
       " 'PDO_ReSALT_snagyk_2017_03.nc4',\n",
       " 'PDO_ReSALT_ivotuk_2017_03.nc4',\n",
       " 'PDO_ReSALT_provid_2017_03.nc4',\n",
       " 'PDO_ReSALT_ykdelt_2017_03.nc4',\n",
       " 'PDO_ReSALT_koyukk_2017_03.nc4',\n",
       " 'PDO_ReSALT_wolfcr_2017_03.nc4',\n",
       " 'PDO_ReSALT_nwells_2017_03.nc4',\n",
       " 'PDO_ReSALT_faberl_2017_03.nc4',\n",
       " 'PDO_ReSALT_tukhwy_2017_03.nc4',\n",
       " 'PDO_ReSALT_oldcrA_2017_03.nc4',\n",
       " 'PDO_ReSALT_deltaj_2017_03.nc4',\n",
       " 'PDO_ReSALT_ambler_2017_03.nc4',\n",
       " 'PDO_ReSALT_scoaoi_2017_03.nc4',\n",
       " 'PDO_ReSALT_barrow_2017_03.nc4',\n",
       " 'PDO_ReSALT_yflats_2017_03.nc4',\n",
       " 'PDO_ReSALT_bonanz_2017_03.nc4',\n",
       " 'PDO_ReSALT_toolik_2017_03.nc4',\n",
       " 'PDO_ReSALT_aklavi_2017_03.nc4',\n",
       " 'PDO_ReSALT_poorma_2017_03.nc4',\n",
       " 'PDO_ReSALT_coldfo_2017_03.nc4',\n",
       " 'PDO_ReSALT_ftreso_2017_03.nc4',\n",
       " 'PDO_ReSALT_kluanB_2017_03.nc4',\n",
       " 'PDO_ReSALT_watson_2017_03.nc4',\n",
       " 'PDO_ReSALT_snarer_2017_03.nc4',\n",
       " 'PDO_ReSALT_katmai_2017_03.nc4',\n",
       " 'PDO_ReSALT_kakisB_2017_03.nc4',\n",
       " 'PDO_ReSALT_kakisA_2017_03.nc4',\n",
       " 'PDO_ReSALT_yellow_2017_03.nc4',\n",
       " 'PDO_ReSALT_daring_2017_03.nc4',\n",
       " 'PDO_ReSALT_huslia_2017_03.nc4',\n",
       " 'PDO_ReSALT_kluanA_2017_03.nc4',\n",
       " 'PDO_ReSALT_behcho_2017_03.nc4',\n",
       " 'PDO_ReSALT_scotty_2017_03.nc4',\n",
       " 'PDO_ReSALT_counci_2017_03.nc4',\n",
       " 'PDO_ReSALT_sriver_2017_03.nc4',\n",
       " 'PDO_ReSALT_inigok_2017_03.nc4',\n",
       " 'PDO_ReSALT_anaktu_2017_03.nc4',\n",
       " 'PDO_ReSALT_fsmitS_2017_03.nc4']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(V3_path)\n",
    "os.listdir(V3_path)\n",
    "\n",
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a bunch of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdo_version_3_netcdf_file(filename, print_flag):\n",
    "    # this function reads data from standard PDO version 3 data file\n",
    "\n",
    "    # open netcdf file\n",
    "    ncfile = Dataset(filename) # Dataset is a function that's part of the netCDF4 library\n",
    "    \n",
    "    # check if file has vwc data because not all swaths have VWC\n",
    "    has_vwc=False\n",
    "    for var in ncfile.variables.keys():\n",
    "        if (var == 'mv_alt'):\n",
    "            has_vwc = True\n",
    "\n",
    "    # read the variables\n",
    "    nc_alt = ncfile.variables['alt']\n",
    "    nc_sub = ncfile.variables['sub'] # subsidence\n",
    "    if has_vwc:\n",
    "        nc_vwc = ncfile.variables['mv_alt'] # vwc if has\n",
    "    nc_lon = ncfile.variables['lon'] # array with longitude at each point, 2D\n",
    "    nc_lat = ncfile.variables['lat']\n",
    "\n",
    "    # determine dimensions of swath\n",
    "    nscan_loc, nspot_loc = nc_alt.shape\n",
    "    numpt_loc  = nscan_loc*nspot_loc  # total number of points\n",
    "    \n",
    "    # allocate output arrays\n",
    "    # '_loc' means local to this function\n",
    "    alt_loc = np.zeros((numpt_loc))\n",
    "    sub_loc = np.zeros((numpt_loc))\n",
    "    vwc_loc = np.zeros((numpt_loc))\n",
    "    lon_loc = np.zeros((numpt_loc))\n",
    "    lat_loc = np.zeros((numpt_loc))\n",
    "\n",
    "    # reshape arrays from 2D swath to 1D vector\n",
    "    # vectors are much easier to handle, especially for statistics\n",
    "    alt_loc = np.array(nc_alt[:,:]).reshape(-1)\n",
    "    sub_loc = np.array(nc_sub[:,:]).reshape(-1)\n",
    "    if has_vwc:\n",
    "        vwc_loc = np.array(nc_vwc[:,:]).reshape(-1)\n",
    "    lon_loc = np.array(nc_lon[:,:]).reshape(-1)\n",
    "    lat_loc = np.array(nc_lat[:,:]).reshape(-1)\n",
    "\n",
    "    # close netcdf file\n",
    "    ncfile.close()\n",
    "    \n",
    "    # Print stuff, if desired\n",
    "    if(print_flag):\n",
    "        print(' ')\n",
    "        print('Read Filename: ', filename)\n",
    "        print('nscan: ', nscan_loc)\n",
    "        print('nspot: ', nspot_loc)\n",
    "        print('numpt: ', numpt_loc)\n",
    "        print('lon min: ', min(lon_loc), ' max: ', max(lon_loc))\n",
    "        print('lat min: ', min(lat_loc), ' max: ', max(lat_loc))\n",
    "        print('ALT min: ', min(alt_loc), ' max: ', max(alt_loc))\n",
    "        print('sub min: ', min(sub_loc), ' sub: ', max(sub_loc))\n",
    "        print('vwc min: ', min(vwc_loc), ' sub: ', max(vwc_loc))\n",
    "\n",
    "    return nscan_loc, nspot_loc, alt_loc, sub_loc, vwc_loc, lon_loc, lat_loc, has_vwc\n",
    "\n",
    "def vector_statistics_row(vector, swath, var, units, print_header):\n",
    "    # calculates statistics of vector\n",
    "    # prints standard statistics as a table\n",
    "    # assumes all missing values removed from vector\n",
    "    \n",
    "    # Table header\n",
    "    head = []\n",
    "    head.append(\"Swath\")\n",
    "    head.append(\"Var\")\n",
    "    head.append(\"Units\")\n",
    "    head.append(\"Num\")\n",
    "    head.append(\"Ave\")\n",
    "    head.append(\"Std\")\n",
    "    head.append(\"Min\")\n",
    "    head.append(\"5%\")\n",
    "    head.append(\"25%\")\n",
    "    head.append(\"Med\")\n",
    "    head.append(\"75%\")\n",
    "    head.append(\"95%\")\n",
    "    head.append(\"Max\")\n",
    "\n",
    "    # calculate statistics\n",
    "    stats=np.zeros((10))\n",
    "    stats[0]=len(vector)              # total number of points in vector\n",
    "    stats[1]=np.mean(vector)          # mean\n",
    "    stats[2]=np.std(vector)           # standard deviation\n",
    "    stats[3]=min(vector)              # minimum value\n",
    "    stats[4]=np.percentile(vector,5)  # 5th percentile\n",
    "    stats[5]=np.percentile(vector,25) # 25th percentile\n",
    "    stats[6]=np.median(vector)        # median\n",
    "    stats[7]=np.percentile(vector,75) # 75th percentile\n",
    "    stats[8]=np.percentile(vector,95) # 95th percentile\n",
    "    stats[9]=max(vector)              # maximum value\n",
    "\n",
    "    # Print table header\n",
    "    if (print_header):\n",
    "        print(f'{head[0]:>10}', f'{head[1]:>4}', f'{head[2]:>4}', f'{head[3]:>7}', f'{head[4]:>7}', f'{head[5]:>7}', f'{head[6]:>7}', \\\n",
    "              f'{head[7]:>7}', f'{head[8]:>7}', f'{head[9]:>7}', f'{head[10]:>7}', f'{head[11]:>7}', f'{head[12]:>10}')\n",
    "    print(f'{swath[0:10]:>10}',f'{var[0:4]:>4}', f'{units[0:4]:>4}',f'{stats[0]:7.0f}', f'{stats[1]:7.4f}', f'{stats[2]:7.4f}', \\\n",
    "          f'{stats[3]:7.4f}', f'{stats[4]:7.4f}', f'{stats[5]:7.4f}', f'{stats[6]:7.4f}', f'{stats[7]:7.4f}', \\\n",
    "          f'{stats[8]:7.4f}', f'{stats[9]:7.4f}' )\n",
    "\n",
    "    return\n",
    "\n",
    "def append_vector2_to_end_of_vector1(vector1, vector2, missing, print_flag):\n",
    "    # Appends vector2 on the end of vector1\n",
    "    # returns updated vector1\n",
    "    \n",
    "    # lenth of updated vector\n",
    "    vec1_len = len(vector1) # number of points vector1\n",
    "    vec2_len = len(vector2) # number of points vector2\n",
    "    vec1_len_new = vec1_len + vec2_len\n",
    "\n",
    "    # new vector1\n",
    "    vec1_new = np.zeros((vec1_len_new))\n",
    "\n",
    "    # loop through vector2\n",
    "    count=0  # number of valid value pairs\n",
    "    for ipt in range(vec2_len):\n",
    "        count = vec1_len + ipt\n",
    "        vec1_new[count] = vector2[ipt]\n",
    "\n",
    "    if (print_flag):\n",
    "        print('New Vector lenth: ', vec1_len_new)\n",
    "    \n",
    "    return vec1_len_new, vec1_new\n",
    "\n",
    "def match_two_vectors(vector1, vector2, missing, print_flag):\n",
    "    # identifies all valid matching pairs of values between vector1 and vector2\n",
    "    # valid means both vectors not equal to missing\n",
    "    # returns two vectors containing only valid matching value pairs\n",
    "    # assumes both vectors have the same length\n",
    "    \n",
    "    # define local variables\n",
    "    vec_len = len(vector1)          # number of points\n",
    "    vec1_temp = np.zeros((vec_len)) # temporary holding vector\n",
    "    vec2_temp = np.zeros((vec_len)) # temporary holding vector\n",
    "\n",
    "    # loop through vector\n",
    "    count=0  # number of valid value pairs\n",
    "    for ipt in range(vec_len):\n",
    "        if (vector1[ipt] != missing and vector2[ipt] != missing ):\n",
    "            vec1_temp[count] = vector1[ipt]\n",
    "            vec2_temp[count] = vector2[ipt]\n",
    "            count = count+1\n",
    "\n",
    "    if (print_flag):\n",
    "        print('match_two_vectors num pts before filter: ', vec_len)\n",
    "        print('match_two_vectors num valid pairs: ', count)\n",
    "    \n",
    "    # output filtered vvalid pairs\n",
    "    vec1_filt = np.zeros((count))\n",
    "    vec2_filt = np.zeros((count))\n",
    "    vec1_filt = vec1_temp[0:count]\n",
    "    vec2_filt = vec2_temp[0:count]\n",
    "    \n",
    "    return count, vec1_filt, vec2_filt\n",
    "\n",
    "def Filter_vector(vector, missing, print_flag):\n",
    "    # filters out all missing values in vector\n",
    "    # returns a vector containing only valid values\n",
    "    \n",
    "    # define local variables\n",
    "    vec_len = len(vector)          # number of points\n",
    "    vec_temp = np.zeros((vec_len)) # temporary holding vector\n",
    "\n",
    "    # loop through vector\n",
    "    count=0  # number of valid values\n",
    "    for ipt in range(vec_len):\n",
    "        if (vector[ipt] != missing):\n",
    "            vec_temp[count] = vector[ipt]\n",
    "            count = count+1\n",
    "\n",
    "    if (print_flag):\n",
    "        print('Filter_vector num pts before filter: ', vec_len)\n",
    "        print('Filter_vector num pts after filter: ', count)\n",
    "    \n",
    "    # output filtered vector\n",
    "    vec_filt = np.zeros((count))\n",
    "    vec_filt = vec_temp[0:count]\n",
    "    \n",
    "    return count, vec_filt\n",
    "\n",
    "def histogram_plot(vector, title, xlabel, bmin, bmax, bdelta, filename, display):\n",
    "    # calculates histogram of vector\n",
    "    color = []\n",
    "    color.append(\"black\")\n",
    "    N, bins, patches = plt.hist(vector, bins=np.arange(bmin, 1.01*bmax, step=bdelta), range=[bmin,bmax], density=True, color=color[0])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Percent\")\n",
    "    plt.savefig(filename)\n",
    "    if display:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def dual_histogram_plot(vector1, vector2, vector3, bmin, bmax, bdelta, title, xlabel, labels, legend, filename, display):\n",
    "    # plots three histograms on same plot\n",
    "    color = []\n",
    "    color.append(\"black\")\n",
    "    color.append(\"red\")\n",
    "    color.append(\"blue\")\n",
    "    color.append(\"green\")\n",
    "    color.append(\"magenta\")\n",
    "    plt.hist(vector1, bins=np.arange(bmin, 1.01*bmax, step=bdelta), range=[bmin,bmax], label=labels[0], density=True, histtype = 'step', color=color[0])\n",
    "    plt.hist(vector2, bins=np.arange(bmin, 1.01*bmax, step=bdelta), range=[bmin,bmax], label=labels[1], density=True, histtype = 'step', color=color[1])\n",
    "    plt.hist(vector3, bins=np.arange(bmin, 1.01*bmax, step=bdelta), range=[bmin,bmax], label=labels[2], density=True, histtype = 'step', color=color[2])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Percent\")\n",
    "    plt.legend(loc=legend)\n",
    "    plt.savefig(filename)\n",
    "    if display:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_scatter(xval, yval, title, xlab, xmin,xmax, deltax, ylab, ymin,ymax, deltay, filename, display):\n",
    "    # creats XY scatter plot\n",
    "    color = []\n",
    "    color.append(\"black\")\n",
    "    plt.xlabel(xlab)\n",
    "    plt.ylabel(ylab)\n",
    "    plt.title(title)\n",
    "    plt.xlim((xmin,xmax))\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.xticks(np.arange(xmin, 1.01*xmax, step=deltax))\n",
    "    plt.yticks(np.arange(ymin, 1.001*ymax, step=deltay))\n",
    "    plt.scatter(xval, yval, s = 1, color=color[0])\n",
    "    plt.grid(True)\n",
    "    plt.savefig(filename)\n",
    "    if display:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_scatter_two(xval1, yval1, xval2, yval2, title, xlab, xmin,xmax, deltax, ylab, ymin,ymax, deltay, labels, legend, filename, display):\n",
    "    # creates XY scatter plot of two sets of variables\n",
    "    color = []\n",
    "    color.append(\"black\")\n",
    "    color.append(\"red\")\n",
    "    plt.xlabel(xlab)\n",
    "    plt.ylabel(ylab)\n",
    "    plt.title(title)\n",
    "    plt.xlim((xmin,xmax))\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.xticks(np.arange(xmin, 1.01*xmax, step=deltax))\n",
    "    plt.yticks(np.arange(ymin, 1.001*ymax, step=deltay))\n",
    "    plt.scatter(xval1, yval1, s = 1, color=color[0], label=labels[0])\n",
    "    plt.scatter(xval2, yval2, s = 1, color=color[1], label=labels[1])\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc=legend)\n",
    "    plt.savefig(filename)\n",
    "    if display:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_lines(line, numcol, xmin,xmax, deltax, ymin,ymax, deltay,labx, laby, title, labels, legend, filename):\n",
    "    # plots numcol lines on a single plot\n",
    "    color = []\n",
    "    color.append(\"black\")\n",
    "    color.append(\"red\")\n",
    "    color.append(\"blue\")\n",
    "    color.append(\"green\")\n",
    "    color.append(\"magenta\")\n",
    "    color.append(\"orange\")\n",
    "    color.append(\"turquoise\")\n",
    "    color.append(\"lime\")\n",
    "    color.append(\"purple\")\n",
    "    color.append(\"tomato\")\n",
    "    color.append(\"gold\")\n",
    "    plt.xlabel(labx)\n",
    "    plt.ylabel(laby)\n",
    "    plt.title(title)\n",
    "    plt.xlim((xmin,xmax))\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.xticks(np.arange(xmin, 1.001*xmax, step=deltax))\n",
    "    plt.yticks(np.arange(ymin, 1.00001*ymax, step=deltay))\n",
    "    for ilin in range(1,numcol):\n",
    "        if ilin != 50:\n",
    "            plt.plot(line[:, 0],line[:, ilin], color=color[ilin-1], label=labels[ilin-1])\n",
    "        if ilin == 50:\n",
    "            plt.scatter(line[:, 0], line[:, ilin], s = 1, color=color[ilin-1], label=labels[ilin-1])\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc=legend)\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "def plot_contour(xval, yval, zval, xmin,xmax, deltax, ymin,ymax, deltay,cmin, cmax, deltac, labx, laby, labcon, title, filename):\n",
    "    # creates a contour plot\n",
    "    plt.xlabel(labx)\n",
    "    plt.ylabel(laby)\n",
    "    plt.title(title)\n",
    "    plt.xlim((xmin,xmax))\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.xticks(np.arange(xmin, 1.001*xmax, step=deltax))\n",
    "    plt.yticks(np.arange(ymin, 1.001*ymax, step=deltay))\n",
    "    levels = (np.arange(cmin, 1.001*cmax, step=deltac))\n",
    "    cont = plt.contourf(xval, yval, zval, levels=levels)\n",
    "    cbar = plt.colorbar(cont)\n",
    "    cbar.ax.set_ylabel(labcon)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "def farm_to_2d_pdf(vector1, vector2, xvec, yvec, pdf, missing, print_flag):\n",
    "    # identifies all valid matching pairs of values between vector1 and vector2\n",
    "    # counts them in 2-dimensional pdf\n",
    "    # valid means both vectors not equal to missing\n",
    "    # returns updated pdf\n",
    "    # assumes both vectors have the same length\n",
    "    \n",
    "    # define local variables\n",
    "    vec_len = len(vector1) # number of points\n",
    "    numpts_xvec = len(xvec)\n",
    "    numpts_yvec = len(yvec)\n",
    "    x_min = xvec[0]\n",
    "    y_min = yvec[0]\n",
    "    delta_x = xvec[1] - xvec[0]\n",
    "    delta_y = yvec[1] - yvec[0]\n",
    "\n",
    "    # loop through vector\n",
    "    count=0  # number of valid value pairs\n",
    "    for ipt in range(vec_len):\n",
    "        if (vector1[ipt] != missing and vector2[ipt] != missing ):\n",
    "            x_indx = int((vector1[ipt]-x_min)/delta_x)\n",
    "            y_indx = int((vector2[ipt]-y_min)/delta_y)\n",
    "            if (x_indx <= numpts_xvec and y_indx <= numpts_yvec):\n",
    "                pdf[y_indx][x_indx] = pdf[y_indx][x_indx] + 1\n",
    "                count = count+1\n",
    "\n",
    "    if (print_flag):\n",
    "        print('farm_to_2d_pdf num valid pairs: ', count)\n",
    "    \n",
    "    return pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the swath files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chevak 6142.0\n",
      "denali 81369.0\n",
      "kougar 81369.0\n",
      "noatak 81369.0\n",
      "lclark 81369.0\n",
      "gdhope 81369.0\n",
      "dhorse 81369.0\n",
      "oldcrB 81369.0\n",
      "wriglN 81369.0\n",
      "mcpher 81369.0\n",
      "fsmitN 81369.0\n",
      "teller 81369.0\n",
      "atqasu 81369.0\n",
      "snagyk 81369.0\n",
      "ivotuk 81369.0\n",
      "provid 81369.0\n",
      "ykdelt 81369.0\n",
      "koyukk 81369.0\n",
      "wolfcr 81369.0\n",
      "nwells 81369.0\n",
      "faberl 91489.0\n",
      "tukhwy 91489.0\n",
      "oldcrA 91489.0\n",
      "deltaj 97323.0\n",
      "ambler 97323.0\n",
      "scoaoi 97323.0\n",
      "barrow 97323.0\n",
      "yflats 97323.0\n",
      "bonanz 97323.0\n",
      "toolik 97323.0\n",
      "aklavi 97323.0\n",
      "poorma 97323.0\n",
      "coldfo 97323.0\n",
      "ftreso 97323.0\n",
      "kluanB 97323.0\n",
      "watson 97323.0\n",
      "snarer 119809.0\n",
      "katmai 119809.0\n",
      "kakisB 119809.0\n",
      "kakisA 119809.0\n",
      "yellow 119809.0\n",
      "daring 136954.0\n",
      "huslia 136954.0\n",
      "kluanA 136954.0\n",
      "behcho 136954.0\n",
      "scotty 136954.0\n",
      "counci 136954.0\n",
      "sriver 136954.0\n",
      "inigok 136954.0\n"
     ]
    }
   ],
   "source": [
    "# set program control flags\n",
    "do_2d_pdf    = True   # make 2_D pdfs\n",
    "composite    = False   # make multi-swath composite vector\n",
    "print_flag   = False  # print detailed diagnostics\n",
    "plot_hist    = False   # make histograms of variables \n",
    "plot_scat    = False   # make scatterplots\n",
    "display      = True   # display plots to screne as well as to a file\n",
    "calc_stats   = False  # calculate statistics of each variable\n",
    "print_header = True   # print statistics header (always set to true here)\n",
    "missing = -9999.      # standard PDO missing value\n",
    "\n",
    "# setup the pdf\n",
    "if do_2d_pdf:\n",
    "    numpt_pdf = 100\n",
    "    pdf_alt_lat = np.zeros((numpt_pdf,numpt_pdf))\n",
    "    lat_pdf = np.zeros((numpt_pdf))\n",
    "    alt_pdf = np.zeros((numpt_pdf))\n",
    "    delta =1.6/float(numpt_pdf)\n",
    "    alt_pdf = np.arange(0, 1.6, step=delta)\n",
    "    delta =20/float(numpt_pdf)\n",
    "    lat_pdf = np.arange(55, 75, step=delta)\n",
    "\n",
    "if composite:\n",
    "    first_file = True\n",
    "\n",
    "filter_data = False\n",
    "if calc_stats:\n",
    "    filter_data = true\n",
    "if plot_hist:\n",
    "    filter_data = true\n",
    "if plot_scat:\n",
    "    filter_data = true\n",
    "\n",
    "# loop through the files\n",
    "num_files=51 #51\n",
    "for ifile in range(num_files):\n",
    "    # read swath\n",
    "    filename=V3_path+file_list[ifile]\n",
    "    temp = file_list[ifile]\n",
    "    swath=temp[11:17]\n",
    "    nscan, nspot, alt, sub, vwc, lon, lat, has_vwc = read_pdo_version_3_netcdf_file(filename, print_flag)\n",
    "\n",
    "    # GET COPERNICUS DEM\n",
    "    toplat = np.amax(lat)\n",
    "    botlat = np.amin(lat)\n",
    "    leflon = np.amin(lon)\n",
    "    riglon = np.amax(lon)\n",
    "    #outdemfile = \n",
    "   # copcommand = r\"/Users/elizabethwig/OneDrive - Stanford/Stanford_Research/PDO synthesis paper/\" + \"DEM/createDEMcop.py\" +\" \"+\"dem.rsc\"+\" \"+\"elevation.dem.rsc\"+\" \"+str(toplat)+\" \"+str(botlat)+\" \"+str(leflon)+\" \"+str(riglon)\n",
    "   # print(copcommand)\n",
    "   # subprocess.run(copcommand)\n",
    "    \n",
    "    # create a pdf\n",
    "    if do_2d_pdf:\n",
    "        pdf_alt_lat = farm_to_2d_pdf(alt, lat, alt_pdf, lat_pdf, pdf_alt_lat, missing, print_flag)\n",
    "        print(swath, np.max(pdf_alt_lat))\n",
    "\n",
    "\n",
    "    # Combine all swaths into one huge ass vector\n",
    "    # note this can choke the program\n",
    "    if composite:\n",
    "        if not first_file:\n",
    "            tot_nrec, alt_mult = append_vector2_to_end_of_vector1(alt_mult, alt, missing, print_flag)\n",
    "            tot_nrec, sub_mult = append_vector2_to_end_of_vector1(sub_mult, sub, missing, print_flag)\n",
    "            tot_nrec, vwc_mult = append_vector2_to_end_of_vector1(vwc_mult, vwc, missing, print_flag)\n",
    "            tot_nrec, lon_mult = append_vector2_to_end_of_vector1(lon_mult, lon, missing, print_flag)\n",
    "            tot_nrec, lat_mult = append_vector2_to_end_of_vector1(lat_mult, lat, missing, print_flag)\n",
    "        if first_file:\n",
    "            alt_mult = alt\n",
    "            sub_mult = sub\n",
    "            vwc_mult = vwc\n",
    "            lon_mult = lon\n",
    "            lat_mult = lat\n",
    "            first_file = False\n",
    "            tot_nrec = len(lat)\n",
    "    \n",
    "    # filter out missing values\n",
    "    if filter_data:\n",
    "        num_alt, alt_filt = Filter_vector(alt, missing, print_flag)\n",
    "        num_sub, sub_filt = Filter_vector(sub, missing, print_flag)\n",
    "        alt_filt = alt_filt*100 # convert ALT to cm\n",
    "        sub_filt = sub_filt*100 # convert subsidence to cm\n",
    "        if has_vwc:\n",
    "            num_vwc, vwc_filt = Filter_vector(vwc, missing, print_flag)\n",
    "\n",
    "    # calculate swath statistics\n",
    "    if calc_stats:\n",
    "        var='ALT'\n",
    "        units='(cm)'\n",
    "        vector_statistics_row(alt_filt, swath, var, units, print_header)\n",
    "        print_header=False\n",
    "\n",
    "        var='Sub'\n",
    "        units='(cm)'\n",
    "        vector_statistics_row(sub_filt, swath, var, units, print_header)\n",
    "\n",
    "        if has_vwc:\n",
    "            var='VWC'\n",
    "            units='(-)'\n",
    "            vector_statistics_row(vwc_filt, swath, var, units, print_header)\n",
    "\n",
    "        var='Lon'\n",
    "        units='(deg)'\n",
    "        vector_statistics_row(lon, swath, var, units, print_header)\n",
    "\n",
    "        var='Lat'\n",
    "        units='(deg)'\n",
    "        vector_statistics_row(lat, swath, var, units, print_header)\n",
    "\n",
    "    # plot Histograms\n",
    "    if plot_hist:\n",
    "        title = swath + ' ALT'\n",
    "        xlabel='ALT (cm)'\n",
    "        bmin = 0.\n",
    "        bmax = 150.\n",
    "        bdelta = 2.\n",
    "        filename = out_path + 'hist_alt_' + swath +'.png'\n",
    "        histogram_plot(alt_filt, title, xlabel, bmin, bmax, bdelta, filename, display)\n",
    "\n",
    "        title = swath + ' Seasonal Subsidence'\n",
    "        xlabel='Subsidence (cm)'\n",
    "        bmin = 0.\n",
    "        bmax = 6.\n",
    "        bdelta = .02\n",
    "        filename = out_path + 'hist_sub_' + swath +'.png'\n",
    "        histogram_plot(sub_filt, title, xlabel, bmin, bmax, bdelta, filename, display)\n",
    "\n",
    "        if has_vwc:\n",
    "            title = swath + ' Volumetric Water Content'\n",
    "            xlabel='VWC (-)'\n",
    "            bmin = 0.\n",
    "            bmax = 1.\n",
    "            bdelta = .01\n",
    "            filename = out_path + 'hist_vwc_' + swath +'.png'\n",
    "            histogram_plot(vwc_filt, title, xlabel, bmin, bmax, bdelta, filename, display)\n",
    "\n",
    "    if plot_scat:\n",
    "        n_match, alt_match, sub_match = match_two_vectors(alt, sub, missing, print_flag)\n",
    "        alt_match = alt_match*100 # convert ALT to cm\n",
    "        sub_match = sub_match*100 # convert subsidence to cm\n",
    "        title='ALT vs. Subsidence'\n",
    "        xlab='Subsidence (cm)'\n",
    "        xmin=0.\n",
    "        xmax=6.\n",
    "        deltax=1.\n",
    "        ylab='ALT (cm)'\n",
    "        ymin=0.\n",
    "        ymax=150.\n",
    "        deltay=20.\n",
    "        filename= out_path + 'scat_alt_sub_'+swath+'.png'\n",
    "        plot_scatter(sub_match, alt_match, title, xlab, xmin,xmax, deltax, ylab, ymin,ymax, deltay, filename, display)    \n",
    "\n",
    "        if has_vwc:\n",
    "            title='ALT vs. VWC'\n",
    "            xlab='VWC (-)'\n",
    "            xmin=0.\n",
    "            xmax=1.\n",
    "            deltax=.2\n",
    "            ylab='ALT (cm)'\n",
    "            ymin=0.\n",
    "            ymax=150.\n",
    "            deltay=20.\n",
    "            filename= out_path + 'scat_alt_vwc_'+swath+'.png'\n",
    "            plot_scatter(vwc_filt, alt_filt, title, xlab, xmin,xmax, deltax, ylab, ymin,ymax, deltay, filename, display)    \n",
    "\n",
    "# overall multi-swath\n",
    "if composite:\n",
    "    n_match, alt_match, lat_match = match_two_vectors(alt_mult, lat_mult, missing, print_flag)\n",
    "    alt_match = alt_match*100 # convert ALT to cm\n",
    "    if calc_stats:\n",
    "        swath = 'All'\n",
    "        var='ALT'\n",
    "        units='(m)'\n",
    "        vector_statistics_row(alt_match, swath, var, units, print_header)\n",
    "\n",
    "        var='lat'\n",
    "        units='(deg)'\n",
    "        vector_statistics_row(lat_match, swath, var, units, print_header)\n",
    "\n",
    "    title='ALT vs. latitude'\n",
    "    xlab='ALT (cm)'\n",
    "    xmin=0.\n",
    "    xmax=160\n",
    "    deltax=20.\n",
    "    ylab='Latitude (deg)'\n",
    "    ymin=50.\n",
    "    ymax=80.\n",
    "    deltay=5.\n",
    "    filename= out_path + 'scat_alt_sub_'+swath+'.png'\n",
    "    plot_scatter(alt_match, lat_match, title, xlab, xmin,xmax, deltax, ylab, ymin,ymax, deltay, filename, display)    \n",
    "\n",
    "if do_2d_pdf:\n",
    "    # alt_pdf, lat_pdf, pdf_alt_lat\n",
    "    total = np.sum(pdf_alt_lat)\n",
    "    pdf_alt_lat = pdf_alt_lat/total*100\n",
    "    pdf_masked = np.ma.masked_where(pdf_alt_lat == 0. , pdf_alt_lat)\n",
    "    xmin  =0\n",
    "    xmax  =1.6\n",
    "    deltax=.2\n",
    "    ymin  =56\n",
    "    ymax  =72\n",
    "    deltay=2.\n",
    "    cmin = 0.\n",
    "    cmax = np.max(pdf_alt_lat)\n",
    "    deltac =cmax/10\n",
    "    title='ALT vs Latitude'\n",
    "    labx=\"ALT (m)\"\n",
    "    laby=\"Latitude (deg)\"\n",
    "    labcon='frequency (%)'\n",
    "    filename= out_path + 'pdf_alt_lat_'+swath+'.png'\n",
    "    plot_contour(alt_pdf, lat_pdf, pdf_masked, xmin,xmax, deltax, ymin,ymax, deltay,cmin, cmax, deltac,labx, laby, labcon, title, filename)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
